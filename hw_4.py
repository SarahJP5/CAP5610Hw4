# -*- coding: utf-8 -*-
"""hw 4

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GwpSpNuku_eZwuMIZo5mr4nGdJW12pOa
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from numpy import dot
from numpy.linalg import norm


def euclidean(x,y):
  val = np.sqrt( np.sum( (x-y)**2) )
  return val

def cosine(x,y):
  num = dot(x, y)/(norm(x)*norm(y))
  num = 1 - num
  return num

def jaccard(x,y):
  max = np.fmax(x,y)
  sumMax = np.sum(max)

  min = np.fmin(x,y)
  sumMin = np.sum(min)

  return ( 1 - (sumMin / sumMax) )
  

#calculate sse 
def sseCalc(centers, clusters, dataIn):
  sum = 0
  sse = 0
  for i in range(10):
    dists = []
    for j in range(len(clusters[i])):
      currentCluster = clusters[i]
      dists.append( euclidean( centers[i], dataIn[ currentCluster[j] ] ) ) 

    sum = ( np.sum( (dists) ) )
    sse += ( sum / len(clusters[i]) )
    
  sse = (sse / 10)
  return sse 
 

def updateClusters(centers, dataIn, k):
  #create a list of lists to store our cluster information
  #stores the index of which data points are in which cluster 
  newClusters = [[] for i in range(k)]

  #looping through our data to find the closest center to each
  for i, dataPoint in enumerate(dataIn):

    #calculates distance of our ith data point to eacvh center and finds the closest one 
    #dists = [euclidean(dataPoint, tempC) for tempC in centers]
    #dists = [cosine(dataPoint, tempC) for tempC in centers]
    dists = [jaccard(dataPoint, tempC) for tempC in centers]
    nearestCIndex = np.argmin(dists)


    #stores i(uindex of the data point) into our cluster list in the appropriate cluster 
    newClusters[nearestCIndex].append(i)

  return newClusters

def updateMeans(dataIn, clusters, k, features):
  newCenters = np.zeros((k, features))

  #looping through our clusters, to calculate the average of each one 
  for i, currentCluster in enumerate(clusters):
    mean = np.mean(dataIn[currentCluster], axis = 0)

    newCenters[i] = mean

  return newCenters 



#read in data and assign our k = 10

dataIn = pd.read_csv('data.csv')
dataIn = dataIn.to_numpy()
data, features = dataIn.shape
k = 10

#pick k random indeces to be our initial centers
initCentersIndex = np.random.choice(data, k, replace = False)

#getting the data points that correspond to those indeces 
initCenters = [dataIn[i] for i in initCentersIndex]

  
sse = 100000000
iter = 0
while True:
  
  #assigning data points to the closest center
  clusters = updateClusters(initCenters, dataIn, k)

  #calculating the new centers based of the mean of each cluster 
  newCenters =  updateMeans(dataIn, clusters, k, features)

  #loop to see if our centers have moved
  #if they have not changed, we have converged and we can exit 
  centerDistances = [euclidean(newCenters[i], initCenters[i]) for i in range(k)]
  sum = np.sum(centerDistances)

  Newsse = sseCalc(newCenters, clusters, dataIn)

  if(iter > 100): #or (Newsse > sse) or (iter > 100) or (sum == 0):
    break
  else: 
    initCenters = newCenters
    sse = Newsse
    iter += 1

  


assignments = [0] * data
for i, currentcluster in enumerate(clusters):
  for j in currentcluster: 
    assignments[j] = i

sse = sseCalc(newCenters, clusters, dataIn)

print("sse:" , sse)
print("num iterations: ", iter)
print("assigned clusters", assignments)

